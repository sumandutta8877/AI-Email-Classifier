{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-11T18:45:08.236144Z","iopub.execute_input":"2021-07-11T18:45:08.236461Z","iopub.status.idle":"2021-07-11T18:45:08.256931Z","shell.execute_reply.started":"2021-07-11T18:45:08.236388Z","shell.execute_reply":"2021-07-11T18:45:08.256010Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/enron-email-dataset/emails.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import model_selection, naive_bayes, svm\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport email\nimport re\n\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstopwords = stopwords.words('english') ","metadata":{"execution":{"iopub.status.busy":"2021-07-11T18:45:08.258206Z","iopub.execute_input":"2021-07-11T18:45:08.258560Z","iopub.status.idle":"2021-07-11T18:45:09.635901Z","shell.execute_reply.started":"2021-07-11T18:45:08.258524Z","shell.execute_reply":"2021-07-11T18:45:09.635005Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/enron-email-dataset/emails.csv\")\n\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T18:45:10.302853Z","iopub.execute_input":"2021-07-11T18:45:10.303168Z","iopub.status.idle":"2021-07-11T18:45:32.604329Z","shell.execute_reply.started":"2021-07-11T18:45:10.303138Z","shell.execute_reply":"2021-07-11T18:45:32.603551Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                       file                                            message\n0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file</th>\n      <th>message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>allen-p/_sent_mail/1.</td>\n      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>allen-p/_sent_mail/10.</td>\n      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>allen-p/_sent_mail/100.</td>\n      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>allen-p/_sent_mail/1000.</td>\n      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>allen-p/_sent_mail/1001.</td>\n      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"catagories = []\nfor name in data['file']:\n  name=name.split('/')\n  catagories.append(name[1])\n\ndata['catagory'] = catagories\nlabels = list(data['catagory'].unique())\n\nprint(data['catagory'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-07-11T18:52:31.076692Z","iopub.execute_input":"2021-07-11T18:52:31.077036Z","iopub.status.idle":"2021-07-11T18:52:31.564520Z","shell.execute_reply.started":"2021-07-11T18:52:31.076996Z","shell.execute_reply":"2021-07-11T18:52:31.563611Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"all_documents                       128103\ndiscussion_threads                   58609\nsent                                 57653\ndeleted_items                        51356\ninbox                                44859\n                                     ...  \nsynfuel                                  1\nassociations                             1\nblack_hills                              1\ngovernment_affairs_group_reports         1\nsithe                                    1\nName: catagory, Length: 1427, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"selected_catagories =  ['discussion_threads', 'personal', 'meetings', 'logistics', 'calendar', 'archiving', 'california', 'power', 'deal_communication', 'resumes']\n\ndata = data[data['catagory'].isin(selected_catagories)]","metadata":{"execution":{"iopub.status.busy":"2021-07-11T18:52:34.849712Z","iopub.execute_input":"2021-07-11T18:52:34.850044Z","iopub.status.idle":"2021-07-11T18:52:34.994805Z","shell.execute_reply.started":"2021-07-11T18:52:34.850011Z","shell.execute_reply":"2021-07-11T18:52:34.993929Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#mail body\nemail_body = []\n\nfor mail in data['message']:\n  mail = email.message_from_string(mail)  \n\n  # getting message body  \n  message_body = mail.get_payload()\n  \n  email_body.append(message_body)\n\ndata['message_body'] = email_body\n\n\n#getting headers\n\nheaders = {\"Date\":[], \"Subject\":[], \"X-Folder\":[], \"X-From\":[], \"X-To\":[]}\nfor mail in data['message']:\n  mail = email.message_from_string(mail)  \n\n  #get other headers\n  for header in headers.keys():\n    headers[header].append(mail.get(header))\n\nfor key in headers.keys():\n  data[key] = headers[key]\ndata['Date'] = pd.to_datetime(data['Date'])\n\nprint(data.head())","metadata":{"execution":{"iopub.status.busy":"2021-07-11T18:52:37.516193Z","iopub.execute_input":"2021-07-11T18:52:37.516549Z","iopub.status.idle":"2021-07-11T18:53:28.849709Z","shell.execute_reply.started":"2021-07-11T18:52:37.516513Z","shell.execute_reply":"2021-07-11T18:53:28.848735Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"                                 file  \\\n1593    allen-p/discussion_threads/1.   \n1594   allen-p/discussion_threads/10.   \n1595  allen-p/discussion_threads/100.   \n1596  allen-p/discussion_threads/101.   \n1597  allen-p/discussion_threads/102.   \n\n                                                message            catagory  \\\n1593  Message-ID: <20379972.1075855673249.JavaMail.e...  discussion_threads   \n1594  Message-ID: <21833620.1075855673443.JavaMail.e...  discussion_threads   \n1595  Message-ID: <25754034.1075855675456.JavaMail.e...  discussion_threads   \n1596  Message-ID: <29444139.1075855675477.JavaMail.e...  discussion_threads   \n1597  Message-ID: <6888095.1075855675499.JavaMail.ev...  discussion_threads   \n\n                                           message_body  \\\n1593  Naomi,\\n\\nThe two analysts that I have had con...   \n1594  Jeff/Brenda:\\n\\nPlease authorize the following...   \n1595  ---------------------- Forwarded by Phillip K ...   \n1596  ---------------------- Forwarded by Phillip K ...   \n1597  ---------------------- Forwarded by Phillip K ...   \n\n                           Date                   Subject  \\\n1593  1999-12-10 07:00:00-08:00                             \n1594  2000-01-13 02:30:00-08:00                       eol   \n1595  2000-08-16 03:59:00-07:00  ENA Management Committee   \n1596  2000-08-20 10:38:00-07:00              Daily Report   \n1597  2000-08-20 10:39:00-07:00              Daily Report   \n\n                                               X-Folder           X-From  \\\n1593  \\Phillip_Allen_Dec2000\\Notes Folders\\Discussio...  Phillip K Allen   \n1594  \\Phillip_Allen_Dec2000\\Notes Folders\\Discussio...  Phillip K Allen   \n1595  \\Phillip_Allen_Dec2000\\Notes Folders\\Discussio...  Phillip K Allen   \n1596  \\Phillip_Allen_Dec2000\\Notes Folders\\Discussio...  Phillip K Allen   \n1597  \\Phillip_Allen_Dec2000\\Notes Folders\\Discussio...  Phillip K Allen   \n\n                       X-To  \n1593         Naomi Johnston  \n1594  Brenda Flores-Cuellar  \n1595             Ina Rangel  \n1596   pallen70@hotmail.com  \n1597   pallen70@hotmail.com  \n","output_type":"stream"}]},{"cell_type":"code","source":"print(data.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T18:54:22.702510Z","iopub.execute_input":"2021-07-11T18:54:22.702832Z","iopub.status.idle":"2021-07-11T18:54:22.709650Z","shell.execute_reply.started":"2021-07-11T18:54:22.702801Z","shell.execute_reply":"2021-07-11T18:54:22.708530Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"(78251, 9)\n","output_type":"stream"}]},{"cell_type":"code","source":"data.dropna(inplace = True)\nprint(data.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T18:54:26.069860Z","iopub.execute_input":"2021-07-11T18:54:26.070192Z","iopub.status.idle":"2021-07-11T18:54:26.245836Z","shell.execute_reply.started":"2021-07-11T18:54:26.070159Z","shell.execute_reply":"2021-07-11T18:54:26.244902Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"(78232, 9)\n","output_type":"stream"}]},{"cell_type":"code","source":"#Removing non alphanumeric characters\ndef clean_text(text):\n  cleanText = text.lower()\n  cleanText = re.sub(r'[\\W\\d]', \" \", cleanText)  \n\n  return cleanText\n\n#Removing stop words\ndef stop_word_removal(text):\n  tokens = [token for token in text if token not in stopwords]\n  return tokens\n\n#Tokenizing\ndef tokenize(text):\n  tokens = text.split(\" \")\n  return tokens\n\nheaders = [\"Subject\", \"X-Folder\", \"X-From\", \"X-To\", \"message_body\"]\n\ntokens = [] \n\nfor i in range(data.shape[0]):\n  tokens_i = []\n  for header in headers:\n    tokens_h = clean_text(data[header].values[i])\n    tokens_h = tokenize(tokens_h)\n    tokens_h = stop_word_removal(tokens_h)\n\n    tokens_i.extend(tokens_h)\n\n  tokens.append(tokens_i)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T18:54:27.751006Z","iopub.execute_input":"2021-07-11T18:54:27.751341Z","iopub.status.idle":"2021-07-11T18:56:20.292514Z","shell.execute_reply.started":"2021-07-11T18:54:27.751308Z","shell.execute_reply":"2021-07-11T18:56:20.291630Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"for i in range(len(tokens)):\n  tokens[i].remove(\"\")\n  tokens[i] = \" \".join(tokens[i])\n\ndata['final_text'] = tokens\n\nprint(data['final_text'])","metadata":{"execution":{"iopub.status.busy":"2021-07-11T18:56:24.670128Z","iopub.execute_input":"2021-07-11T18:56:24.670449Z","iopub.status.idle":"2021-07-11T18:56:26.219168Z","shell.execute_reply.started":"2021-07-11T18:56:24.670417Z","shell.execute_reply":"2021-07-11T18:56:26.218280Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"1593       phillip_allen_dec     notes folders discussio...\n1594      eol phillip_allen_dec     notes folders discus...\n1595      ena management committee phillip_allen_dec    ...\n1596      daily report phillip_allen_dec     notes folde...\n1597      daily report phillip_allen_dec     notes folde...\n                                ...                        \n516850    updated edcc ecc pricing discussion  exmerge  ...\n516851    aes project  tolling interest  exmerge   zuffe...\n516852    transfer enron direct contracts ed  marking in...\n516971    momentum motor cars john_zufferlie_dec     not...\n516972    new email address john_zufferlie_dec     notes...\nName: final_text, Length: 78232, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = model_selection.train_test_split(data['final_text'], data['catagory'], test_size=0.3)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T19:12:42.080003Z","iopub.execute_input":"2021-07-11T19:12:42.080348Z","iopub.status.idle":"2021-07-11T19:12:42.103175Z","shell.execute_reply.started":"2021-07-11T19:12:42.080318Z","shell.execute_reply":"2021-07-11T19:12:42.102320Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# x_train, x_val, y_train, y_val = model_selection.train_test_split(x_train, y_train, test_size=0.4)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T18:56:37.746555Z","iopub.execute_input":"2021-07-11T18:56:37.746881Z","iopub.status.idle":"2021-07-11T18:56:37.765696Z","shell.execute_reply.started":"2021-07-11T18:56:37.746853Z","shell.execute_reply":"2021-07-11T18:56:37.764876Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"Encoder = LabelEncoder()\ny_train = Encoder.fit_transform(y_train)\ny_test = Encoder.fit_transform(y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T19:12:45.880430Z","iopub.execute_input":"2021-07-11T19:12:45.880799Z","iopub.status.idle":"2021-07-11T19:12:45.919860Z","shell.execute_reply.started":"2021-07-11T19:12:45.880768Z","shell.execute_reply":"2021-07-11T19:12:45.918829Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# y_val = Encoder.fit_transform(y_val)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T18:56:40.739247Z","iopub.execute_input":"2021-07-11T18:56:40.739581Z","iopub.status.idle":"2021-07-11T18:56:40.756167Z","shell.execute_reply.started":"2021-07-11T18:56:40.739549Z","shell.execute_reply":"2021-07-11T18:56:40.755288Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"Tfidf_vect = TfidfVectorizer()\n\nTfidf_vect.fit(data['final_text'])\n\nx_train = Tfidf_vect.transform(x_train)\nx_test = Tfidf_vect.transform(x_test)\n# x_val = Tfidf_vect.transform(x_val)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T19:12:59.867095Z","iopub.execute_input":"2021-07-11T19:12:59.867415Z","iopub.status.idle":"2021-07-11T19:13:33.549835Z","shell.execute_reply.started":"2021-07-11T19:12:59.867383Z","shell.execute_reply":"2021-07-11T19:13:33.548976Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"Naive = naive_bayes.MultinomialNB()\nNaive.fit(x_train, y_train)\n\npredictions_NB = Naive.predict(x_test)\nprint(\"Naive Bayes Accuracy Score -> \", accuracy_score(predictions_NB, y_test)*100)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T19:13:39.170364Z","iopub.execute_input":"2021-07-11T19:13:39.170712Z","iopub.status.idle":"2021-07-11T19:13:39.387797Z","shell.execute_reply.started":"2021-07-11T19:13:39.170680Z","shell.execute_reply":"2021-07-11T19:13:39.385562Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Naive Bayes Accuracy Score ->  78.18065615679592\n","output_type":"stream"}]},{"cell_type":"code","source":"SVM = svm.SVC(C=1, kernel='linear', degree=3, gamma='auto')\nSVM.fit(x_train, y_train)\n\npredictions_SVM = SVM.predict(x_test)\nprint(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, y_test)*100)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T19:13:41.166255Z","iopub.execute_input":"2021-07-11T19:13:41.166602Z","iopub.status.idle":"2021-07-11T19:47:32.631067Z","shell.execute_reply.started":"2021-07-11T19:13:41.166567Z","shell.execute_reply":"2021-07-11T19:47:32.630225Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"SVM Accuracy Score ->  94.65274818917767\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}